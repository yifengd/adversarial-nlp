{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yifengd/adversarial-nlp/blob/main/defenses/wdr/Training_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers >> /dev/null"
      ],
      "metadata": {
        "id": "qoKKd0WsqpU8"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKRSbmu4Hmag"
      },
      "source": [
        "# WDR Training and Testing (with Improvements)\n",
        "\n",
        "This script can be used to train and test the classifier on original and adversarial samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XAxbz_6GqSkr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "import importlib\n",
        "from copy import copy\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "94JcqwW7qUjQ",
        "outputId": "d94a014f-4791-45c6-cbc5-1282c00d7bb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODE = \"TEST\" # TRAIN\n",
        "\n",
        "MULTIWORD_MASK_N = 2\n",
        "MLM_MASK = False"
      ],
      "metadata": {
        "id": "F43W8uJZBpzg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvP1fooCfR7D"
      },
      "source": [
        "# Loading and transforming data into logits differences\n",
        "\n",
        "The first step is transforming our dataframe into logits differences for each original and adversarial sentence. For this, it is required to execute the model for each sentence with substitutions as explained in the paper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "m-5rqMHqfR7D",
        "outputId": "8893aacf-5699-4d74-be58-cfe039e949d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Older attacks\n",
            "Raw from benchmark\n",
            "Old\n",
            "ag-news_2000_train_styleadv_distilbert.csv\n",
            "ag-news_dev_2000_styleadv_distilbert.csv\n",
            "imdb_test_100_styleadv_distilbert.csv\n",
            "imdb_train_1000_styleadv_distilbert.csv\n",
            "sst2_test_pruthi_bert.csv\n",
            "sst2_train_2000_styleadv_bert.csv\n",
            "sst2_train_pruthi_bert.csv\n",
            "sst2_val_pruthi_bert.csv\n",
            "sst2_val_styleadv_bert.csv\n"
          ]
        }
      ],
      "source": [
        "SAMPLES_PATH = '/content/drive/MyDrive/AdversarialXAI/Adversarial Samples'\n",
        "\n",
        "# Print available setups for testing\n",
        "for i in os.listdir(SAMPLES_PATH):\n",
        "    if not i.startswith('.'): # Don't print system files\n",
        "        print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "x7lVq4pAfR7E"
      },
      "outputs": [],
      "source": [
        "# Select the configuration for training\n",
        "dataset_path = 'sst2_train_2000_styleadv_bert.csv' # or 'agnews_pwws_distilbert.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "n3Iqx5dFfR7E",
        "outputId": "ed6e1056-c5ac-4f50-8eb4-a9412682d99c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model architecture: bert\n",
            "Dataset: SST-2\n"
          ]
        }
      ],
      "source": [
        "# Obtain model from test config\n",
        "model_arch = dataset_path.replace(\".csv\", \"\").split('_')[-1]\n",
        "dataset = dataset_path.split('_')[0]\n",
        "if dataset == \"sst2\":\n",
        "  dataset = \"SST-2\"\n",
        "print(\"Model architecture:\", model_arch)\n",
        "print(\"Dataset:\", dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "t4Q51W0ofR7F"
      },
      "outputs": [],
      "source": [
        "def load_textattack_local_model(model_arch, dataset):\n",
        "    \n",
        "    def load_module_from_file(file_path):\n",
        "        \"\"\"Uses ``importlib`` to dynamically open a file and load an object from\n",
        "        it.\"\"\"\n",
        "        temp_module_name = f\"temp_{time.time()}\"\n",
        "\n",
        "        spec = importlib.util.spec_from_file_location(temp_module_name, file_path)\n",
        "        module = importlib.util.module_from_spec(spec)\n",
        "        spec.loader.exec_module(module)\n",
        "        return module\n",
        "    \n",
        "    m = load_module_from_file(f'../{model_arch}_{dataset}_textattack.py')\n",
        "    model = getattr(m, 'model')\n",
        "    \n",
        "    return model, None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "90TzS-60fR7F"
      },
      "outputs": [],
      "source": [
        "def load_hugging_face_model(model_arch, dataset):\n",
        "    # Import the model used for generating the adversarial samples.\n",
        "    # Correctly, set up imports, model and tokenizer depending on the model you generated the samples on.\n",
        "    \n",
        "    if model_arch == 'distilbert':\n",
        "        from transformers import DistilBertConfig as config, DistilBertTokenizer as tokenizer, AutoModelForSequenceClassification as auto_model\n",
        "    elif model_arch == 'bert':\n",
        "        from transformers import BertConfig as config, BertTokenizer as tokenizer, AutoModelForSequenceClassification as auto_model\n",
        "    \n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    tokenizer = tokenizer.from_pretrained(f\"textattack/{model_arch}-base-uncased-{dataset}\")\n",
        "    model = auto_model.from_pretrained(f\"textattack/{model_arch}-base-uncased-{dataset}\").to(device)\n",
        "    \n",
        "    return model, tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "iujKfMatfR7G"
      },
      "outputs": [],
      "source": [
        "# Models available in hugging-face are executed differently from LSTM and CNN. Choose automatically the configuration and load model + tokenizer.\n",
        "textattack_local_models = ['lstm', 'cnn']\n",
        "\n",
        "if model_arch in textattack_local_models:\n",
        "    hugging_face_model = False\n",
        "    model, tokenizer = load_textattack_local_model(model_arch, dataset)\n",
        "\n",
        "else:\n",
        "    hugging_face_model = True\n",
        "    model, tokenizer = load_hugging_face_model(model_arch, dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1XxOsu_4EgE"
      },
      "source": [
        "# Loading data\n",
        "\n",
        "Read into a dataframe your original and adversarial samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "twkc6DQIfR7G",
        "outputId": "3ead7a13-e6c8-4c1f-9c87-cd9ea0a2db32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1972, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Read the desired csv file previously generated\n",
        "df = pd.read_csv(f'{SAMPLES_PATH}/{dataset_path}')\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "h3snuVjzfR7H"
      },
      "outputs": [],
      "source": [
        "# Select first entries. Only 3000 will be used but we leave room for false adversarial sentences that will be filtered out later and test set. We reduce size because computations are expensive.\n",
        "# In real setup, the whole file was considered and fixed train and test sets were produced.\n",
        "df = df.head(7000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "y87VzvT1fR7H"
      },
      "outputs": [],
      "source": [
        "# Create batches of non-adversarial sentences\n",
        "# For big models such as BERT, we must divide our input in smaller batches.\n",
        "n = 256 # Size of each batch.\n",
        "batches = [list(df.original_text.values)[i:i + n] for i in range(0, len(df.original_text.values), n)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "xgB0p7VxqENf",
        "outputId": "36461a06-5edb-41ba-9b5c-f40f6fa028b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' elegant visual sense  '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "batches[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "U9w_oE8-fR7H"
      },
      "outputs": [],
      "source": [
        "# Generate predictions for all non-adversarial sentences in our dataset\n",
        "outputs = []\n",
        "\n",
        "if hugging_face_model is True: # Use tokenizer and hugging face pipeline\n",
        "    for b in batches: \n",
        "        input = tokenizer(b, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
        "        with torch.no_grad():\n",
        "            output = model(**input)\n",
        "            outputs.append(output.logits.cpu().numpy())\n",
        "            del input\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "else: # Use local model by simply predicting without tokenization\n",
        "    for b in batches: \n",
        "        output = model(b)\n",
        "        outputs.append(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "frRXf0P9fR7I"
      },
      "outputs": [],
      "source": [
        "# Obtain non-adversarial predictions\n",
        "outputs_flatten = [item for sublist in outputs for item in sublist]\n",
        "predictions = [np.argmax(i) for i in outputs_flatten]\n",
        "\n",
        "# Include prediction for these classes in our DataFrame\n",
        "df['original_class_predicted'] = predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "wqDSHW_nfR7I"
      },
      "outputs": [],
      "source": [
        "# Repeat process for adversarial sentences\n",
        "n = 256\n",
        "batches = [list(df.adversarial_text.values)[i:i + n] for i in range(0, len(df.adversarial_text.values), n)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "nrnkZkTdfR7J"
      },
      "outputs": [],
      "source": [
        "# Generate predictions for all non-adversarial sentences in our dataset\n",
        "outputs = []\n",
        "\n",
        "if hugging_face_model is True: # Use tokenizer and hugging face pipeline\n",
        "    for b in batches: \n",
        "        input = tokenizer(b, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
        "        with torch.no_grad():\n",
        "            output = model(**input)\n",
        "            outputs.append(output.logits.cpu().numpy())\n",
        "            del input\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "else: # Use local model by simply predicting without tokenization\n",
        "    for b in batches: \n",
        "        output = model(b)\n",
        "        outputs.append(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "h1vAsWe9fR7J"
      },
      "outputs": [],
      "source": [
        "# Obtain adversarial predictions\n",
        "outputs_flatten = [item for sublist in outputs for item in sublist]\n",
        "predictions = [np.argmax(i) for i in outputs_flatten]\n",
        "\n",
        "# Include prediction for these classes in our DataFrame\n",
        "df['adversarial_class_predicted'] = predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "YCUrHP-4fR7J"
      },
      "outputs": [],
      "source": [
        "# Select only those sentences for which there was actually a change in the prediction\n",
        "correct = df[(df['original_class_predicted'] != df['adversarial_class_predicted'])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Kzz81OGvfR7J",
        "outputId": "e9fa587d-c25f-44c6-9a19-cb2bd1bf86fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "926"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# Update dataframe and keep only adversarial samples\n",
        "df = correct\n",
        "len(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INb_NMpLfR7K"
      },
      "source": [
        "# Obtain logits\n",
        "Once we have the predictions and actually adversarial sentences, we generate the logits differences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "-FiJMYa7fR7L"
      },
      "outputs": [],
      "source": [
        "original_samples = df.original_text.values\n",
        "adversarial_samples = df.adversarial_text.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "PF7zyw_MfR7L"
      },
      "outputs": [],
      "source": [
        "# Concatenate all original samples and their predictions\n",
        "x = np.concatenate((original_samples, adversarial_samples))\n",
        "y = np.concatenate((np.zeros(len(original_samples)), np.ones(len(adversarial_samples))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "rVzO4b6MfR7L"
      },
      "outputs": [],
      "source": [
        "def obtain_logits(samples, batch_size, model, tokenizer):\n",
        "    \"\"\"\n",
        "    For given samples and model, compute prediction logits.\n",
        "    Input data is splitted in batches.\n",
        "    \"\"\"\n",
        "    batches = [samples[i:i + batch_size] for i in range(0, len(samples), batch_size)]\n",
        "    logits = []\n",
        "\n",
        "    for i, b in enumerate(batches):\n",
        "        print(\"{}/{}\".format(i+1, len(batches)))\n",
        "        if hugging_face_model:\n",
        "            with torch.no_grad():\n",
        "                input = tokenizer(list(b), return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
        "                logits.append(model(**input).logits.cpu().numpy())\n",
        "        else:\n",
        "            logits.append(model(b))\n",
        "\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "OQ229UFNfR7L",
        "outputId": "d4784f19-2ca4-40f5-e18e-b11973a0c8c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/3\n",
            "2/3\n",
            "3/3\n"
          ]
        }
      ],
      "source": [
        "# Compute logits for original sentences\n",
        "batch_size = 350\n",
        "original_logits = obtain_logits(original_samples, batch_size, model, tokenizer)\n",
        "original_logits = np.concatenate(original_logits).reshape(-1, original_logits[0].shape[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "WTj7PW_2fR7M"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "xG4vLDpifR7M",
        "outputId": "1f46768e-9e58-4c21-c64b-2b6f79167759",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/3\n",
            "2/3\n",
            "3/3\n"
          ]
        }
      ],
      "source": [
        "# Compute logits for adversarial sentences\n",
        "batch_size = 350\n",
        "adversarial_logits = obtain_logits(adversarial_samples, batch_size, model, tokenizer)\n",
        "adversarial_logits = np.concatenate(adversarial_logits).reshape(-1, adversarial_logits[0].shape[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "c638-0iafR7M"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ywMSEETffR7M"
      },
      "outputs": [],
      "source": [
        "# Concatenate all logits\n",
        "logits = np.concatenate((original_logits, adversarial_logits))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "rnSx8bUufR7M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8ec4499-2c1a-4c07-c029-49fa29a517a5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' ridiculousness  ',\n",
              " ' profane  ',\n",
              " ' sappiness  ',\n",
              " ' aplenty  ',\n",
              " ' spiffy  ',\n",
              " ' virtuous  ',\n",
              " ' lameness  ',\n",
              " ' old  ',\n",
              " ' miike  ',\n",
              " ' irritates  ',\n",
              " ' disoriented  ',\n",
              " ' uncompromising  ',\n",
              " ' shines  ',\n",
              " ' warmth  ',\n",
              " ' ethereal  ',\n",
              " ' embarrassed  ',\n",
              " ' sleep-inducingly  ',\n",
              " ' paint-by-numbers  ',\n",
              " ' errors  ',\n",
              " ' laughs  ',\n",
              " ' exploitation  ',\n",
              " ' swedish  ',\n",
              " ' faithful  ',\n",
              " ' allusions  ',\n",
              " ' discordant  ',\n",
              " ' faithful................................................................................................................................................................................................................................................................................................................................ ',\n",
              " ' falls  ',\n",
              " ' affectingly  ',\n",
              " ' fiascos  ',\n",
              " ' delicate  ',\n",
              " ' desperate  ',\n",
              " ' deception  ',\n",
              " ' flatula  ',\n",
              " ' ace  ',\n",
              " ' peak  ',\n",
              " ' spontaneous  ',\n",
              " ' metaphor  ',\n",
              " ' cliffhanger  ',\n",
              " ' competently  ',\n",
              " ' overwhelming  ',\n",
              " ' militarism  ',\n",
              " ' emphasized  ',\n",
              " ' positives  ',\n",
              " ' unsubtle  ',\n",
              " ' nonjudgmental  ',\n",
              " ' perfect  ',\n",
              " ' attack  ',\n",
              " ' recommend  ',\n",
              " ' messing  ',\n",
              " ' stabs  ',\n",
              " ' bubbly  ',\n",
              " ' orgy  ',\n",
              " ' well-intentioned  ',\n",
              " ' unhollowing ',\n",
              " ' chokes  ',\n",
              " ' accomplishment  ',\n",
              " ' pleasuring  ',\n",
              " ' unsurprising  ',\n",
              " ' freely  ',\n",
              " ' rae  ',\n",
              " ' wizened  ',\n",
              " ' bloody  ',\n",
              " ' geared  ',\n",
              " ' fraction  ',\n",
              " ' glaring  ',\n",
              " ' least  ',\n",
              " ' rambles  ',\n",
              " ' prominent  ',\n",
              " ' temperature......................................Temperature............................. ',\n",
              " ' drag  ',\n",
              " ' penetrating  ',\n",
              " ' appeals  ',\n",
              " ' freedom  ',\n",
              " ' inventing  ',\n",
              " ' downbeat  ',\n",
              " ' affirming  ',\n",
              " ' nerds  ',\n",
              " ' fearlessness  ',\n",
              " ' fit  ',\n",
              " ' melancholic  ',\n",
              " ' fluttering  ',\n",
              " ' epics  ',\n",
              " ' burns  ',\n",
              " ' a-list  ',\n",
              " ' chris  ',\n",
              " ' crash-and-bash  ',\n",
              " ' sewage  ',\n",
              " ' all-woman  ',\n",
              " ' disappoints  ',\n",
              " ' altered  ',\n",
              " ' flatly  ',\n",
              " ' unbearable  ',\n",
              " ' divine  ',\n",
              " ' concentration  ',\n",
              " ' knockout  ',\n",
              " ' dynamic  ',\n",
              " ' backwater  ',\n",
              " ' goofiest  ',\n",
              " ' meager  ',\n",
              " ' advancing  ',\n",
              " ' misguided  ',\n",
              " ' never  ',\n",
              " ' eyes  ']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# Shuffle data\n",
        "import random\n",
        "c = list(zip(x, y, logits))\n",
        "random.shuffle(c)\n",
        "x, y, logits = zip(*c)\n",
        "[s for s in x if len(s.split()) == 1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4TaXtSZfR7N"
      },
      "source": [
        "## Computing logits difference\n",
        "\n",
        "This is a key step implemented. The main idea is:\n",
        "* For each sentence, replace each word by the `[UNK]` token and compute prediction logits\n",
        "* Using these logits, we can easily compute the saliency of the word as presented in the report.\n",
        "* Then, we sort words by descending saliency.\n",
        "* Finally, compute logits difference for each replacement. This difference is computed as `Logit from class predicted for the whole sentence - Highest remaining logit`\n",
        "\n",
        "More details on these derivations are found in the paper."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "pipe = pipeline('fill-mask', model=f\"distilbert-base-uncased\")"
      ],
      "metadata": {
        "id": "nTDT_OhbigKT"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "_8ScyI0afR7N"
      },
      "outputs": [],
      "source": [
        "def compute_logits_difference(x, logits, y, model, tokenizer, idx, max_sentence_size=512, num_masked=1, mask_fill=None):\n",
        "    n_classes = len(logits[idx])\n",
        "    predicted_class = np.argmax(logits[idx]) # Predicted class for whole sentence using previously computed logits\n",
        "    class_logit = logits[idx][predicted_class] # Store this origianl prediction logit\n",
        "\n",
        "    split_sentence = x[idx].split(' ')[:max_sentence_size] # The tokenizer will only consider 512 words so we avoid computing innecessary logits\n",
        "\n",
        "    new_sentences = []\n",
        "\n",
        "    if mask_fill != None and num_masked > 1:\n",
        "      raise NotImplementedError\n",
        "\n",
        "    if mask_fill != None:\n",
        "      for i, word in enumerate(split_sentence):\n",
        "        new_sentence = copy(split_sentence)\n",
        "        new_sentence[i] = '[MASK]'\n",
        "        new_sentence = ' '.join(new_sentence)\n",
        "        new_sentences.append(new_sentence)\n",
        "    else:\n",
        "      # Here, we replace each word by [UNK] and generate all sentences to consider\n",
        "      for i, word in enumerate(split_sentence[:len(split_sentence) - num_masked + 1]):\n",
        "          new_sentence = copy(split_sentence)\n",
        "          for k in range(num_masked): \n",
        "            new_sentence[i + k] = '[UNK]'\n",
        "          new_sentence = ' '.join(new_sentence)\n",
        "          new_sentences.append(new_sentence)\n",
        "    \n",
        "    if len(new_sentences) == 0:\n",
        "      return torch.zeros(0, 1).to(device), torch.Tensor([y[idx]]).to(device)\n",
        "    \n",
        "    try: \n",
        "      if mask_fill != None:\n",
        "        new_sentences = [m[0]['sequence'] for m in mask_fill(new_sentences)]\n",
        "    except KeyError:\n",
        "      print(new_sentences)\n",
        "\n",
        "    # print(new_sentences[-1])\n",
        "\n",
        "    # We cannot run more than 350 predictions simultaneously because of resources.\n",
        "    # Split in batches if necessary.\n",
        "    # Compute logits for all replacements.\n",
        "    if len(new_sentences) > 200:\n",
        "        logits = []\n",
        "        batches = [new_sentences[i:i + 200] for i in range(0, len(new_sentences), 200)]\n",
        "        for b in batches:\n",
        "            if hugging_face_model: # Use hugging face predictions\n",
        "                batch = tokenizer(b, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
        "                with torch.no_grad():\n",
        "                    logits.append(model(**batch).logits)\n",
        "            else:\n",
        "                logits.append(model(b).to(device))\n",
        "      \n",
        "        if hugging_face_model:\n",
        "            logits = torch.cat(logits)\n",
        "        else:\n",
        "            logits = np.concatenate( logits, axis=0 )\n",
        "            logits = torch.Tensor(logits)\n",
        "    \n",
        "    else: # There's no need to split in batches\n",
        "        if hugging_face_model:\n",
        "            batch = tokenizer(new_sentences, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
        "            with torch.no_grad():\n",
        "                logits = model(**batch).logits\n",
        "            del batch\n",
        "        else:\n",
        "            logits = model(new_sentences)\n",
        "            logits = torch.Tensor(logits)\n",
        "\n",
        "\n",
        "    # Compute saliency\n",
        "    saliency = (class_logit - logits[:,predicted_class]).reshape(-1, 1) # NUM_SENTS x 1\n",
        "\n",
        "    # Append to logits for sorting\n",
        "    data = torch.cat((logits, saliency), 1) # NUM_SENTS x NUM_CLASSES + 1\n",
        "\n",
        "    # Sort by descending saliency\n",
        "    data = torch.stack(sorted(data, key=lambda a: a[n_classes], reverse=True))\n",
        "\n",
        "    # Remove saliency\n",
        "    data = data[:, :n_classes] # NUM_SENTS x NUM_CLASSES\n",
        "\n",
        "    # Fix order: originallly predicted class, other classes\n",
        "    order = [predicted_class] + [i for i in range(n_classes) if i!=predicted_class]\n",
        "    data = torch.index_select(data, 1, torch.LongTensor(order).to(device))  # NUM_SENTS x NUM_CLASSES\n",
        "\n",
        "    # Compute difference between predicted class (always first column) and higher remaining logit\n",
        "    data = data[:, :1].flatten() - torch.max(data[:, 1:], dim=1).values.flatten() # NUM_SENTS\n",
        "\n",
        "    del saliency\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    # Return only logits difference\n",
        "    return data.reshape(-1, 1), torch.Tensor([y[idx]]).to(device) # NUM_SENTS x 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "8dQxs9ETfR7N"
      },
      "outputs": [],
      "source": [
        "def compute_logits_difference_padding(x, logits, y, model, tokenizer, idx, target_size=512, mask_fill=None, num_masked=1):\n",
        "    \"\"\"\n",
        "    This function provides a wrapper for compute_logits_difference and includes padding to computations.\n",
        "    \"\"\"\n",
        "    data, y = compute_logits_difference(x, logits, y, model, tokenizer, idx, target_size, mask_fill=mask_fill, num_masked=num_masked)\n",
        "    data_size = min(512, data.shape[0])\n",
        "    target = torch.zeros(target_size, 1).to(device)\n",
        "    target[:data_size, :] = data\n",
        "\n",
        "    return target, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "WBrFnu75fR7O"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import sys\n",
        "from torch.autograd import Variable\n",
        "\n",
        "class Text(Dataset):\n",
        "    \"\"\"\n",
        "    Dataloader following torch details. Each time we get an item, we will compute\n",
        "    the logits difference.\n",
        "    \"\"\"\n",
        "    def __init__(self, x , logits, y, model, tokenizer, train=True, max_sentence_size=512, multiword_mask=1, mlm_mask=False):\n",
        "        self.logits = logits\n",
        "        self.y = y\n",
        "        self.x = x\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_sentence_size = max_sentence_size\n",
        "        self.multiword_mask = multiword_mask\n",
        "        self.mlm_mask = mlm_mask\n",
        "\n",
        "        if multiword_mask > 1 and mlm_mask:\n",
        "          raise NotImplementedError()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data_components = []\n",
        "\n",
        "        for i in range(1, self.multiword_mask + 1):\n",
        "          data, y = compute_logits_difference_padding(self.x, self.logits, self.y, self.model, self.tokenizer, idx, self.max_sentence_size, num_masked=i)\n",
        "          data = data[:, :1].unsqueeze(0)  # 1 x 512 x 1\n",
        "\n",
        "          data_components.append(data)\n",
        "        \n",
        "        if self.mlm_mask:\n",
        "          data2, _ = compute_logits_difference_padding(self.x, self.logits, self.y, self.model, self.tokenizer, idx, self.max_sentence_size, num_masked=1, mask_fill=pipe)\n",
        "          data2 = data2[:, :1].unsqueeze(0)\n",
        "\n",
        "          data_components.append(data2)\n",
        "        \n",
        "        if len(data_components) == 1:\n",
        "          return data_components[0], y, self.x[idx]\n",
        "        else:\n",
        "          return torch.cat(data_components, dim=1), y, self.x[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "UbwMfB4XfR7O"
      },
      "outputs": [],
      "source": [
        "# torch.multiprocessing.set_start_method('spawn', force=True)\n",
        "\n",
        "# Create the dataloader\n",
        "train_ds = Text(x, logits, y, model, tokenizer, multiword_mask=MULTIWORD_MASK_N, mlm_mask=MLM_MASK)\n",
        "train_loader = DataLoader(dataset=train_ds, batch_size=256, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "d7YUtzPZfR7O"
      },
      "outputs": [],
      "source": [
        "# Define the target DataFrame to structure our data.\n",
        "# It has a column for each input dimension (up to 512) and \n",
        "# it also includes whether it is adversarial or not (y_label) and the sentence from which the logits where extracted\n",
        "\n",
        "dimensions = MULTIWORD_MASK_N * 512\n",
        "if MLM_MASK:\n",
        "  dimensions += 512\n",
        "\n",
        "data_all = pd.DataFrame(columns=[i for i in range(dimensions)]+['y_label', 'sentence'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "QTtHK3nnfR7P",
        "outputId": "f775ab48-0d20-484e-d75f-0241ecad971b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0/8 - 0.0\n",
            "\n",
            "1/8 - 0.125\n",
            "\n",
            "2/8 - 0.25\n",
            "\n",
            "3/8 - 0.375\n",
            "\n",
            "4/8 - 0.5\n",
            "\n",
            "5/8 - 0.625\n",
            "\n",
            "6/8 - 0.75\n",
            "\n",
            "7/8 - 0.875\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Generate logits difference by running the loader.\n",
        "for i, (data, y_label, sentence) in enumerate(train_loader):\n",
        "    print(\"{}/{} - {}\\n\".format(i, len(train_loader), i/len(train_loader)))\n",
        "    for v in range(len(data)):\n",
        "        # Structure data and include in dataframe\n",
        "        row = np.append(data[v].cpu().numpy().reshape(1,-1), np.array([y_label[v].item(), sentence[v]]))\n",
        "        data_all = data_all.append(pd.DataFrame([row], columns=list(data_all)), ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_all"
      ],
      "metadata": {
        "id": "xd3KbYbb2agO",
        "outputId": "b4e84c1b-0e3a-48c1-eb7d-d1e328ff4336",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 942
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               0             1           2           3           4  \\\n",
              "0     -5.8796806    -1.7704885  -1.2715987    1.305377   2.0623434   \n",
              "1     0.48988494     1.7928007   2.7327037    2.785447   3.0047982   \n",
              "2        3.11653     5.0461254   5.0902324    5.204444    5.212596   \n",
              "3      -5.165555    -3.7377172  -1.6726873  -1.6127242  -1.3955364   \n",
              "4       5.643599      6.098986   6.1851697   6.4314985    6.548147   \n",
              "...          ...           ...         ...         ...         ...   \n",
              "1847   2.9246135      3.183181   4.2413945   4.8510456   4.8510456   \n",
              "1848   0.3149402      5.694725   5.7139997   5.8302155    5.939002   \n",
              "1849   1.2095178     3.9293602   4.2312055   5.3438396   5.5033474   \n",
              "1850   1.6187952     5.3177342    5.646173   5.7889147   6.1031427   \n",
              "1851  -3.5368147  -0.013155985  0.12565954  0.81874406    1.566398   \n",
              "\n",
              "                5           6            7             8             9  ...  \\\n",
              "0        5.042874         0.0          0.0           0.0           0.0  ...   \n",
              "1       3.5616093    4.288803    4.3167367      4.362954           0.0  ...   \n",
              "2        5.397453   5.4384794     5.483839      5.418788     5.5473948  ...   \n",
              "3     -0.82567525  -0.9090843  -0.28754684  -0.004408058  -0.018685993  ...   \n",
              "4        6.548147    6.657836    6.6529326     6.7026424     6.8727207  ...   \n",
              "...           ...         ...          ...           ...           ...  ...   \n",
              "1847     5.279681    5.539399    6.3687105           0.0           0.0  ...   \n",
              "1848     6.000313    6.498698    6.4615154           0.0           0.0  ...   \n",
              "1849    6.2454534   6.2620864     7.483782           0.0           0.0  ...   \n",
              "1850    6.2118397    6.219294     6.225162     6.3867736     6.5153356  ...   \n",
              "1851     2.884552    2.884552    6.6673555           0.0           0.0  ...   \n",
              "\n",
              "     1016 1017 1018 1019 1020 1021 1022 1023 y_label  \\\n",
              "0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     1.0   \n",
              "1     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     1.0   \n",
              "2     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0   \n",
              "3     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     1.0   \n",
              "4     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0   \n",
              "...   ...  ...  ...  ...  ...  ...  ...  ...     ...   \n",
              "1847  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0   \n",
              "1848  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     1.0   \n",
              "1849  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     1.0   \n",
              "1850  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0   \n",
              "1851  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0     0.0   \n",
              "\n",
              "                                               sentence  \n",
              "0                        unwelcome, but not unpleasant   \n",
              "1                      dealing with it will be the end   \n",
              "2      future lizard endeavors will need to adhere m...  \n",
              "3      translation...... a routine scary-eyed horror...  \n",
              "4      there 's nothing remotely topical or sexy her...  \n",
              "...                                                 ...  \n",
              "1847             recovering from its demented premise    \n",
              "1848                   the criticism is damn, damn it.   \n",
              "1849            dilates the pleasure of watching them.   \n",
              "1850   has a certain ghoulish fascination , and gene...  \n",
              "1851              believed in their small-budget film    \n",
              "\n",
              "[1852 rows x 1026 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-02dcb0d5-29b7-49bc-b9e6-4b11d1b8e4ae\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>1016</th>\n",
              "      <th>1017</th>\n",
              "      <th>1018</th>\n",
              "      <th>1019</th>\n",
              "      <th>1020</th>\n",
              "      <th>1021</th>\n",
              "      <th>1022</th>\n",
              "      <th>1023</th>\n",
              "      <th>y_label</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-5.8796806</td>\n",
              "      <td>-1.7704885</td>\n",
              "      <td>-1.2715987</td>\n",
              "      <td>1.305377</td>\n",
              "      <td>2.0623434</td>\n",
              "      <td>5.042874</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>unwelcome, but not unpleasant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.48988494</td>\n",
              "      <td>1.7928007</td>\n",
              "      <td>2.7327037</td>\n",
              "      <td>2.785447</td>\n",
              "      <td>3.0047982</td>\n",
              "      <td>3.5616093</td>\n",
              "      <td>4.288803</td>\n",
              "      <td>4.3167367</td>\n",
              "      <td>4.362954</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>dealing with it will be the end</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.11653</td>\n",
              "      <td>5.0461254</td>\n",
              "      <td>5.0902324</td>\n",
              "      <td>5.204444</td>\n",
              "      <td>5.212596</td>\n",
              "      <td>5.397453</td>\n",
              "      <td>5.4384794</td>\n",
              "      <td>5.483839</td>\n",
              "      <td>5.418788</td>\n",
              "      <td>5.5473948</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>future lizard endeavors will need to adhere m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-5.165555</td>\n",
              "      <td>-3.7377172</td>\n",
              "      <td>-1.6726873</td>\n",
              "      <td>-1.6127242</td>\n",
              "      <td>-1.3955364</td>\n",
              "      <td>-0.82567525</td>\n",
              "      <td>-0.9090843</td>\n",
              "      <td>-0.28754684</td>\n",
              "      <td>-0.004408058</td>\n",
              "      <td>-0.018685993</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>translation...... a routine scary-eyed horror...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.643599</td>\n",
              "      <td>6.098986</td>\n",
              "      <td>6.1851697</td>\n",
              "      <td>6.4314985</td>\n",
              "      <td>6.548147</td>\n",
              "      <td>6.548147</td>\n",
              "      <td>6.657836</td>\n",
              "      <td>6.6529326</td>\n",
              "      <td>6.7026424</td>\n",
              "      <td>6.8727207</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>there 's nothing remotely topical or sexy her...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1847</th>\n",
              "      <td>2.9246135</td>\n",
              "      <td>3.183181</td>\n",
              "      <td>4.2413945</td>\n",
              "      <td>4.8510456</td>\n",
              "      <td>4.8510456</td>\n",
              "      <td>5.279681</td>\n",
              "      <td>5.539399</td>\n",
              "      <td>6.3687105</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>recovering from its demented premise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1848</th>\n",
              "      <td>0.3149402</td>\n",
              "      <td>5.694725</td>\n",
              "      <td>5.7139997</td>\n",
              "      <td>5.8302155</td>\n",
              "      <td>5.939002</td>\n",
              "      <td>6.000313</td>\n",
              "      <td>6.498698</td>\n",
              "      <td>6.4615154</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>the criticism is damn, damn it.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1849</th>\n",
              "      <td>1.2095178</td>\n",
              "      <td>3.9293602</td>\n",
              "      <td>4.2312055</td>\n",
              "      <td>5.3438396</td>\n",
              "      <td>5.5033474</td>\n",
              "      <td>6.2454534</td>\n",
              "      <td>6.2620864</td>\n",
              "      <td>7.483782</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>dilates the pleasure of watching them.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1850</th>\n",
              "      <td>1.6187952</td>\n",
              "      <td>5.3177342</td>\n",
              "      <td>5.646173</td>\n",
              "      <td>5.7889147</td>\n",
              "      <td>6.1031427</td>\n",
              "      <td>6.2118397</td>\n",
              "      <td>6.219294</td>\n",
              "      <td>6.225162</td>\n",
              "      <td>6.3867736</td>\n",
              "      <td>6.5153356</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>has a certain ghoulish fascination , and gene...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1851</th>\n",
              "      <td>-3.5368147</td>\n",
              "      <td>-0.013155985</td>\n",
              "      <td>0.12565954</td>\n",
              "      <td>0.81874406</td>\n",
              "      <td>1.566398</td>\n",
              "      <td>2.884552</td>\n",
              "      <td>2.884552</td>\n",
              "      <td>6.6673555</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>believed in their small-budget film</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1852 rows × 1026 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-02dcb0d5-29b7-49bc-b9e6-4b11d1b8e4ae')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-02dcb0d5-29b7-49bc-b9e6-4b11d1b8e4ae button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-02dcb0d5-29b7-49bc-b9e6-4b11d1b8e4ae');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "rfCAOvbHfR7Z"
      },
      "outputs": [],
      "source": [
        "if MODE == \"TRAIN\":\n",
        "  # Divide train and val set\n",
        "  # Make an ad-hoc val set here\n",
        "  data_val = data_all.tail(200)\n",
        "  data_train = data_all.head(len(data_all) - 200)\n",
        "\n",
        "  y = data_train['y_label'].values\n",
        "  x = data_train.drop(columns=['y_label', 'sentence']).values\n",
        "\n",
        "  y_test = data_val['y_label'].values\n",
        "  x_test = data_val.drop(columns=['y_label', 'sentence']).values"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Testing\n",
        "\n",
        "Use for testing an existing model"
      ],
      "metadata": {
        "id": "lEg06hSjFU4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### TESTING MODE\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import pickle\n",
        "\n",
        "if MODE == \"TEST\":\n",
        "  Y_TEST = data_all['y_label'].values\n",
        "  X_TEST = data_all.drop(columns=['y_label', 'sentence']).values\n",
        "\n",
        "  with open(\"/content/drive/MyDrive/AdversarialXAI/Classifiers/WDR/sst2_pruthi_randomforest_distilbertmask.pickle\", 'rb') as f:\n",
        "    cls = pickle.load(f)\n",
        "\n",
        "  print(cls)\n",
        "\n",
        "  preds = cls.predict(X_TEST)\n",
        "\n",
        "  print(classification_report(Y_TEST, preds, digits=3))"
      ],
      "metadata": {
        "id": "RuJi0XwOZT5O"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3WCIbfDGoqG"
      },
      "source": [
        "# Model training and comparison\n",
        "\n",
        "We train different models and compare their performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ftPvIuxmBlS"
      },
      "source": [
        "### Random forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJE-47xY2u_F",
        "outputId": "26319f02-1b73-4446-f466-d37fad44fe63"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(min_samples_leaf=2, min_samples_split=10,\n",
              "                       n_estimators=1600)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Create the model using best parameters found\n",
        "model = RandomForestClassifier(n_estimators=1600,\n",
        "                               min_samples_split=10,\n",
        "                               min_samples_leaf=2,\n",
        "                               max_features='auto',\n",
        "                               max_depth=None, \n",
        "                               bootstrap = True)\n",
        "# Fit on training data\n",
        "model.fit(x, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "9Zgrj0u_3PNM"
      },
      "outputs": [],
      "source": [
        "# Actual class predictions\n",
        "rf_predictions = model.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0163kTVX3Sjo",
        "outputId": "3d380355-6259-45b6-98fb-e9a0fbf30f81"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.745"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "np.sum(rf_predictions==y_test)/len(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuD9VPNdAxh5",
        "outputId": "2971e918-0195-4d46-9ab6-37eac4d80b98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0      0.769     0.748     0.758       107\n",
            "         1.0      0.719     0.742     0.730        93\n",
            "\n",
            "    accuracy                          0.745       200\n",
            "   macro avg      0.744     0.745     0.744       200\n",
            "weighted avg      0.746     0.745     0.745       200\n",
            "\n",
            "[[80 27]\n",
            " [24 69]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(classification_report(y_test, rf_predictions, digits=3))\n",
        "print(confusion_matrix(y_test, rf_predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ji70i7tT4Z4B"
      },
      "source": [
        "### XGBoost\n",
        "\n",
        "Best performing model. Hyperparamter tuning done with Dataiku."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "rDNzQp9d4PP0"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "xyIrUTHJ4i8p"
      },
      "outputs": [],
      "source": [
        "xgb_classifier = xgb.XGBClassifier(\n",
        "                    max_depth=3,\n",
        "                    learning_rate=0.34281802,\n",
        "                    gamma=0.6770816,\n",
        "                    min_child_weight=2.5520658,\n",
        "                    max_delta_step=0.71469694,\n",
        "                    subsample=0.61460966,\n",
        "                    colsample_bytree=0.73929816,\n",
        "                    colsample_bylevel=0.87191725,\n",
        "                    reg_alpha=0.9064181,\n",
        "                    reg_lambda=0.5686102,\n",
        "                    n_estimators=29,\n",
        "                    silent=0,\n",
        "                    nthread=4,\n",
        "                    scale_pos_weight=1.0,\n",
        "                    base_score=0.5,\n",
        "                    missing=None,\n",
        "                  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFRBurXZ4ohr",
        "outputId": "e7d9578f-234a-4cc5-ccc5-e47997cba28a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(colsample_bylevel=0.87191725, colsample_bytree=0.73929816,\n",
              "              gamma=0.6770816, learning_rate=0.34281802,\n",
              "              max_delta_step=0.71469694, min_child_weight=2.5520658,\n",
              "              n_estimators=29, nthread=4, reg_alpha=0.9064181,\n",
              "              reg_lambda=0.5686102, scale_pos_weight=1.0, silent=0,\n",
              "              subsample=0.61460966)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "xgb_classifier.fit(x, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "tfqAluu-4qik"
      },
      "outputs": [],
      "source": [
        "xgb_predictions = xgb_classifier.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wla48ARQA8Ff",
        "outputId": "883def90-d4f3-4db7-addd-39d82cbb85f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0      0.767     0.738     0.752       107\n",
            "         1.0      0.711     0.742     0.726        93\n",
            "\n",
            "    accuracy                          0.740       200\n",
            "   macro avg      0.739     0.740     0.739       200\n",
            "weighted avg      0.741     0.740     0.740       200\n",
            "\n",
            "[[79 28]\n",
            " [24 69]]\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, xgb_predictions, digits=3))\n",
        "print(confusion_matrix(y_test, xgb_predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving model\n",
        "\n",
        "Choose a model to save"
      ],
      "metadata": {
        "id": "5hJySoWFFfOq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "# pickle.dump(model, open(\"/content/drive/MyDrive/AdversarialXAI/Classifiers/WDR/sst2_pruthi_randomforest_distilbertmask.pickle\", \"wb\"))"
      ],
      "metadata": {
        "id": "rWwjYk7q4TnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# xgb_classifier.save_model(\"/content/drive/MyDrive/AdversarialXAI/Classifiers/WDR/sst2_styleadv_2000_xgb_distilbertmask.json\")"
      ],
      "metadata": {
        "id": "Hcdvf-_65iki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7WrC0LE493U"
      },
      "source": [
        "### AdaBoost classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "706A1Vqd43Qf"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-Yl5c-A5BSu"
      },
      "outputs": [],
      "source": [
        "abc = AdaBoostClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IoE3Ku7x5Fic"
      },
      "outputs": [],
      "source": [
        "abc.fit(x, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nxBWTfvA5Snt"
      },
      "outputs": [],
      "source": [
        "abc_predictions = abc.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LvMmHP8X5WD9"
      },
      "outputs": [],
      "source": [
        "np.sum(abc_predictions==y_test)/len(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RbDTgEtUBfWB"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_test, abc_predictions, digits=3))\n",
        "print(confusion_matrix(y_test, abc_predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnN-pUktttZ_"
      },
      "source": [
        "### LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTtL5YVVtvEV"
      },
      "outputs": [],
      "source": [
        "import lightgbm as lgb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NlfaoFqptxLJ"
      },
      "outputs": [],
      "source": [
        "parameters = {\n",
        "    'objective': 'binary',\n",
        "    'application': 'binary',\n",
        "    'metric': ['binary_logloss'],\n",
        "    'num_leaves': 35,\n",
        "    'learning_rate': 0.13,\n",
        "    'verbose': 1\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ClFNYu-OuVWM"
      },
      "outputs": [],
      "source": [
        "train_data = lgb.Dataset(x, label=y)\n",
        "test_data = lgb.Dataset(x_test, label=y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqhNtf00uKwP"
      },
      "outputs": [],
      "source": [
        "lgbm_classifier = lgb.train(parameters,\n",
        "                       train_data,\n",
        "                       valid_sets=test_data,\n",
        "                       num_boost_round=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W78pbOqTuvGh"
      },
      "outputs": [],
      "source": [
        "y_hat = lgbm_classifier.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anci99rWv2ht"
      },
      "outputs": [],
      "source": [
        "y_hat.round()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbDNWdDnvB8A"
      },
      "outputs": [],
      "source": [
        "np.sum(y_hat.round()==y_test)/len(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = y_test.astype(np.float)"
      ],
      "metadata": {
        "id": "Qsf04LB_wW34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ye3J0Xg0Bkko"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_test, y_hat.round(), digits=3))\n",
        "print(confusion_matrix(y_test, y_hat.round()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbkWwRx5BqF4"
      },
      "source": [
        "### SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogcZnorjBrJ7"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "svm_clf = SVC(C=9.0622635,\n",
        "          kernel='rbf',\n",
        "          gamma='scale',\n",
        "          coef0=0.0,\n",
        "          tol=0.001,\n",
        "          probability=True,\n",
        "          max_iter=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qSkHyPdfBt5v"
      },
      "outputs": [],
      "source": [
        "svm_clf.fit(x, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZnyduhaBw_Y"
      },
      "outputs": [],
      "source": [
        "svm_pred = svm_clf.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svm_pred = svm_pred.astype(np.float)"
      ],
      "metadata": {
        "id": "PccsOjyZwys4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-o_M5fQzCBce"
      },
      "outputs": [],
      "source": [
        "np.sum(svm_pred.round()==y_test)/len(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eP4a7L3qCEg9"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_test, svm_pred.round(), digits=3))\n",
        "print(confusion_matrix(y_test, svm_pred.round()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ik1vjAYuURo-"
      },
      "source": [
        "### Perceptron NN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78lnHAv5DDOd"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import sys\n",
        "from torch.autograd import Variable\n",
        "\n",
        "class Text(Dataset):\n",
        "    def __init__(self, x , y):\n",
        "        self.y = y\n",
        "        self.x = x\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data = torch.tensor(self.x[idx].astype('float32')).to(device)\n",
        "        y = torch.tensor(self.y[idx].astype('float32')).unsqueeze(0).to(device)\n",
        "        return data, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93-kIeh_zxW9"
      },
      "outputs": [],
      "source": [
        "train_ds = Text(x, y)\n",
        "train_loader = DataLoader(dataset=train_ds, batch_size=128, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1LHY5faTTNB5"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class BasicModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(BasicModel, self).__init__()\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim  = output_dim\n",
        "\n",
        "        self.fc1 = torch.nn.Linear(self.input_dim, self.hidden_dim)\n",
        "        self.fc2 = torch.nn.Linear(self.hidden_dim, 1)\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return self.sigmoid(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wY2qWHdORCRq"
      },
      "outputs": [],
      "source": [
        "basic_classifier = BasicModel(input_dim=512*1, hidden_dim=50, output_dim=1).to(device)\n",
        "c = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(basic_classifier.parameters(), lr=0.001)\n",
        "\n",
        "train_loss_history = []\n",
        "val_acc_history = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8lYCLAPqRMWo"
      },
      "outputs": [],
      "source": [
        "iter_per_epoch = len(train_loader)\n",
        "num_epochs = 30\n",
        "initial_epoch = 1\n",
        "log_nth = 2\n",
        "storing_frequency = 15\n",
        "checkpoints_path = \"/content/drive/MyDrive/ExplainableAI/Model/Saliency/checkpoints\"\n",
        "\n",
        "for epoch in range(initial_epoch, initial_epoch+num_epochs):\n",
        "    basic_classifier.train()\n",
        "    epoch_losses = []\n",
        "    for i, (data, y_label) in enumerate(train_loader):\n",
        "      optimizer.zero_grad()\n",
        "      out = basic_classifier(data)\n",
        "      loss = c(out, y_label)\n",
        "      epoch_losses.append(loss.item())\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      if (i+1) % log_nth == 0:        \n",
        "          print ('Epoch [{}/{}], Step [{}/{}], Loss for last {} batches: {:.4f}' \n",
        "                  .format(epoch, num_epochs, i+1, iter_per_epoch, log_nth, np.mean(np.array(epoch_losses[-log_nth:]))))\n",
        "          #print_time()\n",
        "      \n",
        "      if (i+1) % storing_frequency == 0:        \n",
        "          print('Storing with loss for last {} batches = {}'.format(storing_frequency, np.mean(np.array(epoch_losses[-storing_frequency:]))))\n",
        "          #print_time()\n",
        "          #torch.save(basic_classifier.state_dict(), checkpoints_path+\"/final_model_epoch_{}_{}.checkpoint\".format(epoch, i+1))\n",
        "  \n",
        "    # Store after whole epoch\n",
        "    print ('Epoch [{}/{}] finished with loss = {:.4f}'.format(epoch, num_epochs, np.mean(np.array(epoch_losses))))\n",
        "    #torch.save(basic_classifier.state_dict(), checkpoints_path+\"/final_model_epoch_{}.checkpoint\".format(epoch))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JUN1zRwzDVmm"
      },
      "outputs": [],
      "source": [
        "nn_pred = basic_classifier(torch.tensor(x_test.astype('float32')).to(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvTcF71WDVmn"
      },
      "outputs": [],
      "source": [
        "nn_pred = nn_pred.flatten().detach().cpu().numpy().round()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iz0OohekDVmo"
      },
      "outputs": [],
      "source": [
        "np.sum(nn_pred==y_test)/len(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGgUvOOkDVmp"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_test, nn_pred, digits=3))\n",
        "print(confusion_matrix(y_test, nn_pred))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6gE_q0NlxHnV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "WDR",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}