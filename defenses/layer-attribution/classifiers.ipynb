{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yifengd/adversarial-nlp/blob/main/defenses/captum/catum.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8LfM1aIkXi8"
      },
      "source": [
        "# Based on: Explain Attacking BERT models using CAptum\n",
        "\n",
        "Captum is a PyTorch library to explain neural networks\n",
        "Here we show a minimal example using Captum to explain BERT models from TextAttack"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChpotvAVkXjO"
      },
      "source": [
        "[![Open Notebook in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/yifengd/adversarial-nlp/blob/main/defenses/captum/catum.ipynb)\n",
        "\n",
        "[![Original Code on GitHub](https://img.shields.io/badge/github-view%20source-black.svg)](https://github.com/QData/TextAttack/blob/master/docs/2notebook/Example_5_Explain_BERT.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnmSJ9wzstDa"
      },
      "outputs": [],
      "source": [
        "!pip install textattack[tensorflow] tensorflow_text==2.10.0b2 captum nltk -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a55MUrxXCmxg",
        "outputId": "9b413518-efb3-4029-e379-fcc922fd8097"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5CMINr0OkXjU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from copy import deepcopy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "# from textattack.datasets import HuggingFaceDataset\n",
        "from textattack.models.wrappers import HuggingFaceModelWrapper\n",
        "# from textattack.models.wrappers import ModelWrapper\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfCIkViJkXjX",
        "outputId": "c1cde1dc-aea5-4962-c2c8-93b248d866a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using accelerator cuda:0\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "else: \n",
        "    device = torch.device(\"cpu\")\n",
        "    \n",
        "print(f\"Using accelerator {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBVf-QDnLifu"
      },
      "source": [
        "## Configure Model and Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wq4Te1nmkXjY"
      },
      "outputs": [],
      "source": [
        "# dataset = HuggingFaceDataset(\"ag_news\", None, \"train\")\n",
        "original_model = AutoModelForSequenceClassification.from_pretrained(\"textattack/bert-base-uncased-ag-news\")\n",
        "original_tokenizer = AutoTokenizer.from_pretrained(\"textattack/bert-base-uncased-ag-news\")\n",
        "model = HuggingFaceModelWrapper(original_model,original_tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjBO2_KZ3onQ",
        "outputId": "c9b3a9ec-3d7a-47ee-a5b3-fc5d29e6f98a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RobertaForSequenceClassification(\n",
            "  (roberta): RobertaModel(\n",
            "    (embeddings): RobertaEmbeddings(\n",
            "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
            "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
            "      (token_type_embeddings): Embedding(1, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): RobertaEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (2): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (3): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (4): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (5): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (6): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (7): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (8): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (9): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (10): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (11): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (classifier): RobertaClassificationHead(\n",
            "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "    (out_proj): Linear(in_features=768, out_features=4, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model.model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cv1a5xv5KRC7"
      },
      "source": [
        "## Load Dataframe with Original and Perturbed Samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8aoU4pjEkN6"
      },
      "outputs": [],
      "source": [
        "DRIVE_PATH = '/content/drive/MyDrive/NLP-Lab/AdversarialXAI'\n",
        "adversarial_df = pd.read_csv(f\"{DRIVE_PATH}/Adversarial Samples/Older attacks/ag-news_pwws_bert.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YkEYBaUZmCuH"
      },
      "outputs": [],
      "source": [
        "def class_name_to_index(class_name):\n",
        "  if class_name == \"World\":\n",
        "    return 0\n",
        "  elif class_name == \"Sports\":\n",
        "    return 1\n",
        "  elif class_name == \"Business\":\n",
        "    return 2\n",
        "  elif class_name == \"Sci/tech\":\n",
        "    return 3\n",
        "  else:\n",
        "    raise ValueError(class_name)\n",
        "\n",
        "adversarial_df['original_class'] = adversarial_df['original_class'].map(class_name_to_index)\n",
        "adversarial_df['adversarial_class'] = adversarial_df['adversarial_class'].map(class_name_to_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "0yeBIIoOE9AB",
        "outputId": "67347ccc-7892-486d-9d32-d10ffd66f327"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6b916f98-b395-4e36-b3a9-f4930c0090c8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>original_text</th>\n",
              "      <th>adversarial_text</th>\n",
              "      <th>original_class</th>\n",
              "      <th>original_confidence</th>\n",
              "      <th>adversarial_class</th>\n",
              "      <th>adversarial_confidence</th>\n",
              "      <th>attack</th>\n",
              "      <th>replace_dict</th>\n",
              "      <th>replace_num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Fed lifts rates a further quarter point By And...</td>\n",
              "      <td>course lifts grass a further quarter taper pas...</td>\n",
              "      <td>2</td>\n",
              "      <td>(100%)</td>\n",
              "      <td>1</td>\n",
              "      <td>(78%)</td>\n",
              "      <td>pwws</td>\n",
              "      <td>{'Fed': 'course', 'rates': 'grass', 'point': '...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Indian-Americans hail Manmohan speech New York...</td>\n",
              "      <td>Indian-Americans come Manmohan delivery New Yo...</td>\n",
              "      <td>0</td>\n",
              "      <td>(100%)</td>\n",
              "      <td>2</td>\n",
              "      <td>(62%)</td>\n",
              "      <td>pwws</td>\n",
              "      <td>{'hail': 'come', 'speech': 'delivery', 'meetin...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Unisys to lay off 1,400 workers Unisys Corp. p...</td>\n",
              "      <td>Unisys to lay off 1,400 workers Unisys Corp. p...</td>\n",
              "      <td>3</td>\n",
              "      <td>(95%)</td>\n",
              "      <td>2</td>\n",
              "      <td>(80%)</td>\n",
              "      <td>pwws</td>\n",
              "      <td>{'cuts': 'skip'}</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Dollar Mired Near Lows Before Jobs Data  LONDO...</td>\n",
              "      <td>Dollar involved Near Low earlier occupation Da...</td>\n",
              "      <td>2</td>\n",
              "      <td>(100%)</td>\n",
              "      <td>0</td>\n",
              "      <td>(97%)</td>\n",
              "      <td>pwws</td>\n",
              "      <td>{'Mired': 'involved', 'Lows': 'Low', 'Before':...</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Keep quiet on U.S. election, Martin tells loos...</td>\n",
              "      <td>sustain calm on uracil.siemens. election, Mart...</td>\n",
              "      <td>0</td>\n",
              "      <td>(100%)</td>\n",
              "      <td>1</td>\n",
              "      <td>(81%)</td>\n",
              "      <td>pwws</td>\n",
              "      <td>{'Keep': 'sustain', 'quiet': 'calm', 'U.S.': '...</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>419</th>\n",
              "      <td>419</td>\n",
              "      <td>EU draft draws fire in Turkey BRUSSELS: Turkey...</td>\n",
              "      <td>EEC potation haulage terminate in Turkey BRUSS...</td>\n",
              "      <td>0</td>\n",
              "      <td>(100%)</td>\n",
              "      <td>2</td>\n",
              "      <td>(69%)</td>\n",
              "      <td>pwws</td>\n",
              "      <td>{'EU': 'EEC', 'draft': 'potation', 'draws': 'h...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>420</th>\n",
              "      <td>420</td>\n",
              "      <td>U.S. Spies on Chat Rooms Could terrorists be p...</td>\n",
              "      <td>u.sec. espy on Chat Rooms Could terrorists be ...</td>\n",
              "      <td>3</td>\n",
              "      <td>(100%)</td>\n",
              "      <td>2</td>\n",
              "      <td>(52%)</td>\n",
              "      <td>pwws</td>\n",
              "      <td>{'U.S.': 'U.sulphur.', 'Spies': 'espy'}</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>421</th>\n",
              "      <td>421</td>\n",
              "      <td>Stocks Climb on Drop in Consumer Prices NEW YO...</td>\n",
              "      <td>Stocks Climb on Drop in Consumer Prices Modern...</td>\n",
              "      <td>0</td>\n",
              "      <td>(100%)</td>\n",
              "      <td>2</td>\n",
              "      <td>(96%)</td>\n",
              "      <td>pwws</td>\n",
              "      <td>{'NEW': 'Modern', 'Stocks': 'line', 'prices......</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>422</th>\n",
              "      <td>422</td>\n",
              "      <td>Sanpaolo and Dexia in merger talks By Reuters ...</td>\n",
              "      <td>Sanpaolo and Dexia in unification dialogue By ...</td>\n",
              "      <td>2</td>\n",
              "      <td>(100%)</td>\n",
              "      <td>0</td>\n",
              "      <td>(99%)</td>\n",
              "      <td>pwws</td>\n",
              "      <td>{'merger': 'unification', 'talks': 'dialogue',...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>423</th>\n",
              "      <td>423</td>\n",
              "      <td>Four men held over Jakarta bomb Four men are a...</td>\n",
              "      <td>quaternary mankind withstand over Jakarta bomb...</td>\n",
              "      <td>0</td>\n",
              "      <td>(100%)</td>\n",
              "      <td>3</td>\n",
              "      <td>(93%)</td>\n",
              "      <td>pwws</td>\n",
              "      <td>{'Four': 'IV', 'men': 'mankind', 'held': 'with...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>424 rows Ã— 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6b916f98-b395-4e36-b3a9-f4930c0090c8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6b916f98-b395-4e36-b3a9-f4930c0090c8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6b916f98-b395-4e36-b3a9-f4930c0090c8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     Unnamed: 0                                      original_text  \\\n",
              "0             0  Fed lifts rates a further quarter point By And...   \n",
              "1             1  Indian-Americans hail Manmohan speech New York...   \n",
              "2             2  Unisys to lay off 1,400 workers Unisys Corp. p...   \n",
              "3             3  Dollar Mired Near Lows Before Jobs Data  LONDO...   \n",
              "4             4  Keep quiet on U.S. election, Martin tells loos...   \n",
              "..          ...                                                ...   \n",
              "419         419  EU draft draws fire in Turkey BRUSSELS: Turkey...   \n",
              "420         420  U.S. Spies on Chat Rooms Could terrorists be p...   \n",
              "421         421  Stocks Climb on Drop in Consumer Prices NEW YO...   \n",
              "422         422  Sanpaolo and Dexia in merger talks By Reuters ...   \n",
              "423         423  Four men held over Jakarta bomb Four men are a...   \n",
              "\n",
              "                                      adversarial_text  original_class  \\\n",
              "0    course lifts grass a further quarter taper pas...               2   \n",
              "1    Indian-Americans come Manmohan delivery New Yo...               0   \n",
              "2    Unisys to lay off 1,400 workers Unisys Corp. p...               3   \n",
              "3    Dollar involved Near Low earlier occupation Da...               2   \n",
              "4    sustain calm on uracil.siemens. election, Mart...               0   \n",
              "..                                                 ...             ...   \n",
              "419  EEC potation haulage terminate in Turkey BRUSS...               0   \n",
              "420  u.sec. espy on Chat Rooms Could terrorists be ...               3   \n",
              "421  Stocks Climb on Drop in Consumer Prices Modern...               0   \n",
              "422  Sanpaolo and Dexia in unification dialogue By ...               2   \n",
              "423  quaternary mankind withstand over Jakarta bomb...               0   \n",
              "\n",
              "    original_confidence  adversarial_class adversarial_confidence attack  \\\n",
              "0                (100%)                  1                  (78%)   pwws   \n",
              "1                (100%)                  2                  (62%)   pwws   \n",
              "2                 (95%)                  2                  (80%)   pwws   \n",
              "3                (100%)                  0                  (97%)   pwws   \n",
              "4                (100%)                  1                  (81%)   pwws   \n",
              "..                  ...                ...                    ...    ...   \n",
              "419              (100%)                  2                  (69%)   pwws   \n",
              "420              (100%)                  2                  (52%)   pwws   \n",
              "421              (100%)                  2                  (96%)   pwws   \n",
              "422              (100%)                  0                  (99%)   pwws   \n",
              "423              (100%)                  3                  (93%)   pwws   \n",
              "\n",
              "                                          replace_dict  replace_num  \n",
              "0    {'Fed': 'course', 'rates': 'grass', 'point': '...            6  \n",
              "1    {'hail': 'come', 'speech': 'delivery', 'meetin...            4  \n",
              "2                                     {'cuts': 'skip'}            1  \n",
              "3    {'Mired': 'involved', 'Lows': 'Low', 'Before':...           13  \n",
              "4    {'Keep': 'sustain', 'quiet': 'calm', 'U.S.': '...           13  \n",
              "..                                                 ...          ...  \n",
              "419  {'EU': 'EEC', 'draft': 'potation', 'draws': 'h...            4  \n",
              "420            {'U.S.': 'U.sulphur.', 'Spies': 'espy'}            2  \n",
              "421  {'NEW': 'Modern', 'Stocks': 'line', 'prices......            3  \n",
              "422  {'merger': 'unification', 'talks': 'dialogue',...            6  \n",
              "423  {'Four': 'IV', 'men': 'mankind', 'held': 'with...            8  \n",
              "\n",
              "[424 rows x 10 columns]"
            ]
          },
          "execution_count": 162,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "adversarial_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oh0H2huPKXq7"
      },
      "source": [
        "## Calculate Attributions in Original and Perturbed Samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VlPgMLg98IcD"
      },
      "outputs": [],
      "source": [
        "from captum.attr import Occlusion, DeepLift, IntegratedGradients, LayerConductance, LayerIntegratedGradients, LayerDeepLiftShap, InternalInfluence, LayerGradientXActivation, LayerActivation\n",
        "from captum.attr import visualization as viz\n",
        "\n",
        "SUM = False\n",
        "\n",
        "def calculate(input_ids,token_type_ids,attention_mask):\n",
        "    #convert back to list of text\n",
        "    return clone.model(input_ids,token_type_ids,attention_mask)[0]\n",
        "\n",
        "clone = deepcopy(model)\n",
        "clone.model.to(device)\n",
        "\n",
        "for text_type in [\"original\", \"adversarial\"]:\n",
        "  # lig = LayerActivation(calculate, clone.model.bert.encoder.layer[8])\n",
        "  lig = LayerIntegratedGradients(calculate, clone.model.bert.encoder.layer[3])\n",
        "  # lig = InternalInfluence(calculate, clone.model.bert.embeddings)\n",
        "  #lig = LayerGradientXActivation(calculate, clone.model.bert.encoder.layer[8])\n",
        "  # lig = LayerDeepLiftShap(calculate, clone.model.bert.embeddings)\n",
        "  # lig = IntegratedGradients(calculate, clone)\n",
        "  # lig = LayerConductance(calculate, clone.model.bert.embeddings)\n",
        "  #lig = DeepLift(calculate, clone.model)\n",
        "\n",
        "  tokens = model.tokenizer([sentence for sentence in adversarial_df[f\"{text_type}_text\"]], padding=\"max_length\", max_length=128, return_tensors=\"pt\").to(device)\n",
        "  adversarial_df[f\"{text_type}_tokens\"] = [tokens[x].tokens for x in range(tokens.input_ids.shape[0])]\n",
        "\n",
        "  # bsl = torch.zeros(tokens['input_ids'].size()).type(torch.LongTensor).to(device)\n",
        "  labels = [i for i in adversarial_df[f\"{text_type}_class\"]]\n",
        "  labels = torch.tensor(labels).to(device)\n",
        "  batch_size = 100\n",
        "\n",
        "  attributions = []\n",
        "\n",
        "  for i in range(0, len(tokens['input_ids']), batch_size): # range((len(tokens['input_ids']) // batch_size) + 1):\n",
        "    attributions_next = lig.attribute(inputs=tokens['input_ids'][i:i+batch_size],\n",
        "                                  #baselines=bsl,\n",
        "                                  additional_forward_args=(tokens['token_type_ids'][i:i+batch_size], tokens['attention_mask'][i:i+batch_size]),\n",
        "                                  #n_steps = 10,\n",
        "                                  target = labels[i:i+batch_size],\n",
        "                                  internal_batch_size=1\n",
        "                                  )\n",
        "    attributions.append(attributions_next)\n",
        "    \n",
        "  attributions = torch.cat(attributions)\n",
        "\n",
        "  # Neuron attribution\n",
        "  for i in range(len(attributions[0][0])):\n",
        "    adversarial_df[f\"{text_type}_attribution_neuron{i}\"] = (attributions[:, :, i] * tokens.attention_mask).cpu().detach().numpy().tolist()\n",
        "\n",
        "  if SUM:\n",
        "    atts = attributions.sum(dim=-1).squeeze(0)\n",
        "    adversarial_df[f\"{text_type}_attribution\"] = (atts * tokens.attention_mask).cpu().detach().numpy().tolist()\n",
        "  else:\n",
        "    atts = attributions\n",
        "    adversarial_df[f\"{text_type}_attribution\"] = (atts * tokens.attention_mask.unsqueeze(-1)).cpu().detach().numpy().tolist()\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiyQIapGXhK-"
      },
      "source": [
        "## Preprocess the Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vy91kadBBJLH"
      },
      "outputs": [],
      "source": [
        "max_tokens_original = adversarial_df[\"original_attribution\"].apply(lambda x: len(x)).max()\n",
        "max_tokens_perturbed = adversarial_df[\"adversarial_attribution\"].apply(lambda x: len(x)).max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qA7rjs0BA88N"
      },
      "outputs": [],
      "source": [
        "def pad_from_middle(x, num_pad):\n",
        "  out = np.zeros(x.shape[0] + num_pad)\n",
        "  middle = int(x.shape[0] / 2)\n",
        "  out[:middle] = x[:middle]\n",
        "  out[middle + num_pad:] = x[middle:]\n",
        "  out[middle:middle + num_pad] = 0\n",
        "  return out\n",
        "\n",
        "def make_samples(df):\n",
        "  X_original = df[\"original_attribution\"].apply(lambda x: np.array(x)).to_numpy()\n",
        "  X_perturbed = df[\"adversarial_attribution\"].apply(lambda x: np.array(x)).to_numpy()\n",
        "\n",
        "  Y_original = np.zeros(X_original.shape[0])\n",
        "  Y_perturbed = np.ones(X_perturbed.shape[0])\n",
        "\n",
        "  X = np.concatenate((X_original, X_perturbed))\n",
        "  Y = np.concatenate((Y_original, Y_perturbed))\n",
        "\n",
        "  Y = Y.astype(int)\n",
        "\n",
        "  # Fix the padding to alywas match n\n",
        "  max_tokens = max(max_tokens_original, max_tokens_perturbed)\n",
        "\n",
        "  # Convert array of arrays to 2D-array\n",
        "  X = np.stack(X)\n",
        "\n",
        "  X = np.sort(X, axis=1)\n",
        "\n",
        "  X, Y = sklearn.utils.shuffle(X, Y, random_state=42)\n",
        "\n",
        "  X = X.reshape(X.shape[0], -1)\n",
        "  return X, Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YKIBxjCT57C1"
      },
      "outputs": [],
      "source": [
        "shuffled_df = adversarial_df.sample(frac=1)\n",
        "train_df = shuffled_df.iloc[:int(len(shuffled_df) * 0.7)]\n",
        "test_df = shuffled_df.iloc[int(len(shuffled_df) * 0.7):]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwlIU3eaXdEO"
      },
      "source": [
        "## Experiment with different Classification Models for the Adversarial Detector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "cvo41t3JPxlH",
        "outputId": "4f8fd705-47b4-4ad7-fe68-6e1024f8b863"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.89      0.91       296\n",
            "           1       0.89      0.93      0.91       296\n",
            "\n",
            "    accuracy                           0.91       592\n",
            "   macro avg       0.91      0.91      0.91       592\n",
            "weighted avg       0.91      0.91      0.91       592\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.70      0.70       128\n",
            "           1       0.70      0.69      0.69       128\n",
            "\n",
            "    accuracy                           0.70       256\n",
            "   macro avg       0.70      0.70      0.70       256\n",
            "weighted avg       0.70      0.70      0.70       256\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1440x1440 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "x_train, y_train = make_samples(train_df)\n",
        "x_test, y_test = make_samples(test_df)\n",
        "\n",
        "cls = RandomForestClassifier(max_depth=4, random_state=42)\n",
        "cls.fit(x_train, y_train)\n",
        "\n",
        "plt.figure(figsize=(20,20))\n",
        "preds = cls.predict(x_test)\n",
        "\n",
        "print(sklearn.metrics.classification_report(y_train, cls.predict(x_train)))\n",
        "print(sklearn.metrics.classification_report(y_test, preds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYcCDtO7KwA2"
      },
      "source": [
        "### Gaussian Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gX6oAraKb-BW",
        "outputId": "049cc96e-e0d0-4808-8653-09019d320fb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.95      0.68       128\n",
            "           1       0.75      0.14      0.24       128\n",
            "\n",
            "    accuracy                           0.55       256\n",
            "   macro avg       0.64      0.55      0.46       256\n",
            "weighted avg       0.64      0.55      0.46       256\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(x_train, y_train)\n",
        "preds = gnb.predict(x_test)\n",
        "print(sklearn.metrics.classification_report(y_test, preds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q79YM560K3wI"
      },
      "source": [
        "### KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnB-kadbe3RG",
        "outputId": "2aff6c36-f302-498e-9250-72d8b42a33fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.61      0.62       128\n",
            "           1       0.62      0.64      0.63       128\n",
            "\n",
            "    accuracy                           0.62       256\n",
            "   macro avg       0.63      0.62      0.62       256\n",
            "weighted avg       0.63      0.62      0.62       256\n",
            "\n"
          ]
        }
      ],
      "source": [
        " from sklearn.neighbors import KNeighborsClassifier\n",
        "KNN = KNeighborsClassifier()\n",
        "KNN.fit(x_train,y_train)\n",
        "preds = KNN.predict(x_test)\n",
        "print(sklearn.metrics.classification_report(y_test, preds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUAJ66skK6WU"
      },
      "source": [
        "### Bernoulli Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHLFYseLe9FL",
        "outputId": "ef8f7344-e6df-48bb-c0dd-bbeb6bf76ef6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.70      0.63       128\n",
            "           1       0.61      0.48      0.54       128\n",
            "\n",
            "    accuracy                           0.59       256\n",
            "   macro avg       0.59      0.59      0.59       256\n",
            "weighted avg       0.59      0.59      0.59       256\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import BernoulliNB\n",
        "BNB = BernoulliNB()\n",
        "BNB.fit(x_train,y_train)\n",
        "preds = BNB.predict(x_test)\n",
        "print(sklearn.metrics.classification_report(y_test, preds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqkPGg8JK83A"
      },
      "source": [
        "### Logistic Regression Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfqzyBkqfA3p",
        "outputId": "895854b5-651b-4ae3-8973-79dd9705c0eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.66      0.56       128\n",
            "           1       0.47      0.30      0.37       128\n",
            "\n",
            "    accuracy                           0.48       256\n",
            "   macro avg       0.48      0.48      0.46       256\n",
            "weighted avg       0.48      0.48      0.46       256\n",
            "\n"
          ]
        }
      ],
      "source": [
        " from sklearn.linear_model import LogisticRegression\n",
        "LR = LogisticRegression(random_state=42)\n",
        "LR.fit(x_train,y_train)\n",
        "preds = LR.predict(x_test)\n",
        "print(sklearn.metrics.classification_report(y_test, preds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cL8n1M6TK-do"
      },
      "source": [
        "### SGD Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvsrlXZwfEvT",
        "outputId": "c033ac3e-83f3-45b7-9a07-74b35cf5186c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.99      0.67       128\n",
            "           1       0.83      0.04      0.07       128\n",
            "\n",
            "    accuracy                           0.52       256\n",
            "   macro avg       0.67      0.52      0.37       256\n",
            "weighted avg       0.67      0.52      0.37       256\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "SGD = SGDClassifier(random_state=42)\n",
        "SGD.fit(x_train, y_train)\n",
        "preds = SGD.predict(x_test)\n",
        "print(sklearn.metrics.classification_report(y_test, preds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbI_Ib-2LDsz"
      },
      "source": [
        "### Support Vector Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1xcihLWfI21",
        "outputId": "5b9b6c24-1cde-4f57-acb3-3aafe35d1660"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.82      0.69       128\n",
            "           1       0.71      0.43      0.53       128\n",
            "\n",
            "    accuracy                           0.62       256\n",
            "   macro avg       0.65      0.62      0.61       256\n",
            "weighted avg       0.65      0.62      0.61       256\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "SVC = SVC(random_state=42)\n",
        "SVC.fit(x_train,y_train)\n",
        "preds = SVC.predict(x_test)\n",
        "print(sklearn.metrics.classification_report(y_test, preds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBL9uE5ALFsG"
      },
      "source": [
        "### Linear Support Vector Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBdWoxg5fMLX",
        "outputId": "89185448-11c9-4605-c7e6-970f5ba63987"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.77      0.69       128\n",
            "           1       0.69      0.53      0.60       128\n",
            "\n",
            "    accuracy                           0.65       256\n",
            "   macro avg       0.66      0.65      0.64       256\n",
            "weighted avg       0.66      0.65      0.64       256\n",
            "\n"
          ]
        }
      ],
      "source": [
        " from sklearn.svm import LinearSVC\n",
        "LSVC = LinearSVC(random_state=42)\n",
        "LSVC.fit(x_train,y_train)\n",
        "preds = LSVC.predict(x_test)\n",
        "print(sklearn.metrics.classification_report(y_test, preds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_kjIvlqLJ5J"
      },
      "source": [
        "### Nu-Support Vector Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHHCiFBwfPW_",
        "outputId": "6a1f112f-7bd5-4113-e401-c161d872561f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.72      0.73       128\n",
            "           1       0.73      0.76      0.74       128\n",
            "\n",
            "    accuracy                           0.74       256\n",
            "   macro avg       0.74      0.74      0.74       256\n",
            "weighted avg       0.74      0.74      0.74       256\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import NuSVC\n",
        "NSVC = NuSVC(random_state=42)\n",
        "NSVC.fit(x_train,y_train)\n",
        "preds = NSVC.predict(x_test)\n",
        "print(sklearn.metrics.classification_report(y_test, preds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVc7TeMbLLhW"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uVvYaUufTb8",
        "outputId": "df960012-36f0-4687-8152-6cecce3de75c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.74      0.73       128\n",
            "           1       0.74      0.72      0.73       128\n",
            "\n",
            "    accuracy                           0.73       256\n",
            "   macro avg       0.73      0.73      0.73       256\n",
            "weighted avg       0.73      0.73      0.73       256\n",
            "\n"
          ]
        }
      ],
      "source": [
        " from sklearn.ensemble import RandomForestClassifier\n",
        "randomF = RandomForestClassifier(random_state=42)\n",
        "randomF.fit(x_train,y_train)\n",
        "preds = randomF.predict(x_test)\n",
        "print(sklearn.metrics.classification_report(y_test, preds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzyCvYspLNX0"
      },
      "source": [
        "### Extra Trees"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWSXFEINfXPJ",
        "outputId": "1b1d009a-4f44-48ef-c6d0-c1a2796c63cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.71      0.73       128\n",
            "           1       0.72      0.75      0.74       128\n",
            "\n",
            "    accuracy                           0.73       256\n",
            "   macro avg       0.73      0.73      0.73       256\n",
            "weighted avg       0.73      0.73      0.73       256\n",
            "\n"
          ]
        }
      ],
      "source": [
        " from sklearn.ensemble import ExtraTreesClassifier\n",
        "extra_tree = ExtraTreesClassifier(random_state=42)\n",
        "extra_tree.fit(x_train,y_train)\n",
        "preds = extra_tree.predict(x_test)\n",
        "print(sklearn.metrics.classification_report(y_test, preds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uiXhGaHLRJP"
      },
      "source": [
        "### NN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "-NrErtt8Mlhg",
        "outputId": "9a544d40-7291-4c75-ad08-baa82d1d0795"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.75      0.75       296\n",
            "           1       0.75      0.77      0.76       296\n",
            "\n",
            "    accuracy                           0.76       592\n",
            "   macro avg       0.76      0.76      0.76       592\n",
            "weighted avg       0.76      0.76      0.76       592\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.54      0.55       128\n",
            "           1       0.56      0.59      0.57       128\n",
            "\n",
            "    accuracy                           0.56       256\n",
            "   macro avg       0.56      0.56      0.56       256\n",
            "weighted avg       0.56      0.56      0.56       256\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1440x1440 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "max_tokens_original = adversarial_df[\"original_attribution_neuron308\"].apply(lambda x: len(x)).max()\n",
        "max_tokens_perturbed = adversarial_df[\"adversarial_attribution_neuron308\"].apply(lambda x: len(x)).max()\n",
        "\n",
        "def pad_from_middle(x, num_pad):\n",
        "  out = np.zeros(x.shape[0] + num_pad)\n",
        "  middle = int(x.shape[0] / 2)\n",
        "  out[:middle] = x[:middle]\n",
        "  out[middle + num_pad:] = x[middle:]\n",
        "  out[middle:middle + num_pad] = 0\n",
        "  return out\n",
        "\n",
        "def make_samples(df):\n",
        "  X_original = df[\"original_attribution_neuron308\"].apply(lambda x: np.array(x)).to_numpy()\n",
        "  X_perturbed = df[\"adversarial_attribution_neuron308\"].apply(lambda x: np.array(x)).to_numpy()\n",
        "\n",
        "  Y_original = np.zeros(X_original.shape[0])\n",
        "  Y_perturbed = np.ones(X_perturbed.shape[0])\n",
        "\n",
        "  X = np.concatenate((X_original, X_perturbed))\n",
        "  Y = np.concatenate((Y_original, Y_perturbed))\n",
        "\n",
        "  Y = Y.astype(int)\n",
        "\n",
        "  # Fix the padding to alywas match n\n",
        "  max_tokens = max(max_tokens_original, max_tokens_perturbed)\n",
        "\n",
        "  # Convert array of arrays to 2D-array\n",
        "  X = np.stack(X)\n",
        "\n",
        "  X = np.sort(X, axis=1)\n",
        "\n",
        "  X, Y = sklearn.utils.shuffle(X, Y, random_state=42)\n",
        "\n",
        "  X = X.reshape(X.shape[0], -1)\n",
        "  return X, Y\n",
        "\n",
        "\n",
        "shuffled_df = adversarial_df.sample(frac=1)\n",
        "train_df = shuffled_df.iloc[:int(len(shuffled_df) * 0.7)]\n",
        "test_df = shuffled_df.iloc[int(len(shuffled_df) * 0.7):]\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "x_train, y_train = make_samples(train_df)\n",
        "x_test, y_test = make_samples(test_df)\n",
        "\n",
        "cls = RandomForestClassifier(max_depth=4, random_state=42)\n",
        "cls.fit(x_train, y_train)\n",
        "\n",
        "plt.figure(figsize=(20,20))\n",
        "preds = cls.predict(x_test)\n",
        "\n",
        "print(sklearn.metrics.classification_report(y_train, cls.predict(x_train)))\n",
        "print(sklearn.metrics.classification_report(y_test, preds))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "oDznrwV4Kh6Y"
      ],
      "machine_shape": "hm",
      "name": "catum_final.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
